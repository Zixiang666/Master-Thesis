# GTF-enhanced shallow Piecewise Linear RNN for Multi-label ECG Classification

[![Paper](https://img.shields.io/badge/Paper-PDF-red)](docs/GTF_shPLRNN_ECG_Research_Report.pdf)
[![Code](https://img.shields.io/badge/Code-Python-blue)](models/gtf_shplrnn/)
[![Data](https://img.shields.io/badge/Data-MIMIC--IV--ECG-green)](https://physionet.org/content/mimic-iv-ecg/1.0/)

This repository contains the experimental code for our research on **GTF-enhanced shallow Piecewise Linear RNN (GTF-shPLRNN)** for automated ECG multi-label classification, achieving **32Ã— parameter efficiency** compared to ResNet-1D while maintaining **88% of its performance**.



## ğŸš€ Quick Start

### Installation

```bash
git clone https://github.com/yourusername/GTF-shPLRNN-ECG-Experiments.git
cd GTF-shPLRNN-ECG-Experiments
pip install -r requirements.txt
```

### Basic Usage

```python
from models.gtf_shplrnn.corrected_gtf_shplrnn import GTFshPLRNN

# Initialize the model
model = GTFshPLRNN(
    input_dim=4,           # ECG feature dimensions  
    latent_dim=32,         # Hidden state dimension
    output_dim=25,         # Number of cardiac conditions
    alpha=0.5              # GTF mixing parameter
)

# Train the model
python models/gtf_shplrnn/robust_plrnn_training.py
```

### Run SOTA Comparison Experiments

```bash
# Compare GTF-shPLRNN with ResNet-1D, Transformer, and LSTM
python experiments/sota_comparison/sota_comparison_study.py

# Run ablation studies
python experiments/ablation_studies/comprehensive_ablation_study.py
```

## ğŸ“ Repository Structure

```
GTF-shPLRNN-ECG-Experiments/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ gtf_shplrnn/              # Core GTF-shPLRNN implementation
â”‚   â”‚   â”œâ”€â”€ corrected_gtf_shplrnn.py    # Main model architecture
â”‚   â”‚   â”œâ”€â”€ robust_plrnn_training.py    # Training pipeline
â”‚   â”‚   â””â”€â”€ adaptive_gtf.py             # Adaptive GTF mechanisms
â”‚   â””â”€â”€ baselines/                # Baseline model implementations
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ sota_comparison/          # State-of-the-art method comparison
â”‚   â”œâ”€â”€ ablation_studies/         # GTF mechanism ablation studies  
â”‚   â””â”€â”€ large_scale_training/     # 800K sample training experiments
â”œâ”€â”€ data_processing/              # Data preprocessing and feature extraction
â”‚   â”œâ”€â”€ scientific_ecg_feature_extractor.py
â”‚   â”œâ”€â”€ extract_comprehensive_ecg_features.py
â”‚   â””â”€â”€ mimic_ecg_refined_labels.py
â”œâ”€â”€ visualization/                # Result visualization and plotting
â”‚   â”œâ”€â”€ create_sota_comparison_plots.py
â”‚   â””â”€â”€ comprehensive_research_achievements_summary.py
â”œâ”€â”€ utils/                        # Utility functions and metrics
â”œâ”€â”€ configs/                      # Configuration files
â”œâ”€â”€ results/                      # Experimental results and checkpoints
â””â”€â”€ docs/                        # Documentation and research paper
 
```

## ğŸ§  Model Architecture

The GTF-shPLRNN introduces a novel **Î±-mixing mechanism** that balances teacher forcing and free-running modes:

```
z_{t+1} = A * z_t + W1 * ReLU(W2 * z_t + h2) + h1 + C * s_t

GTF Loss = Î± * L_teacher + (1-Î±) * L_free_running
```

### Key Features:

- **Generative Teacher Forcing (GTF)**: First application to ECG analysis
- **Shallow Architecture**: Enhanced interpretability without sacrificing performance
- **Parameter Efficiency**: 320Ã— reduction compared to deep models
- **Numerical Stability**: Layer normalization and gradient clipping

## ğŸ¥ Clinical Applications

### Multi-label Disease Classification

Our system supports simultaneous diagnosis of **25 cardiac conditions**:

- **Normal Rhythm**: F1 = 0.81 (excellent specificity)
- **Atrial Fibrillation**: F1 = 0.67 (good sensitivity)  
- **Ventricular Arrhythmia**: F1 = 0.42 (acceptable for rare conditions)
- **Overall Precision**: 0.89 for rare conditions (low false positive rate)

### Deployment Advantages

- âœ… **Edge Computing Ready**: 230KB model size
- âœ… **Real-time Processing**: 2.43ms inference time
- âœ… **Low Power Consumption**: Minimal computational requirements
- âœ… **Integration Friendly**: Compatible with existing ECG systems

## ğŸ“ˆ Experimental Results

### Large-Scale Training (800K Records)

| Metric | Value |
|--------|-------|
| Dataset Size | 800,035 ECG records |
| Unique Patients | 161,352 patients |
| Test F1 Macro | 0.3607 |
| Test F1 Micro | 0.5886 |
| Test Accuracy | **90.48%** |
| Test AUC | 83.52% |
| Training Time | 8.6 minutes (A100 GPU) |


## ğŸ’» System Requirements

- Python 3.8+
- PyTorch 1.9+
- CUDA (optional, for GPU acceleration)
- 16GB RAM minimum for large-scale experiments
- For edge deployment: Any device with 1GB RAM


```

## ğŸ¤ Contributing

We welcome contributions! Please see our contributing guidelines for details.

## ğŸ“§ Contact

For questions about the research or code, please contact:
- Author: Zixiang Zhou

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

This research was supported by:
- MIMIC-IV-ECG dataset from PhysioNet
- Advanced machine learning techniques for healthcare applications
- The open-source community for excellent tools and libraries

