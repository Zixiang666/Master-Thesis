#!/usr/bin/env python3
"""
åŸºäºECGFounderè®ºæ–‡çš„MIMIC-ECGç²¾ç»†åŒ–æ ‡ç­¾ç³»ç»Ÿ
============================================
å‚è€ƒ2410.04133v4.pdfä¸­ECGFounderçš„150ä¸ªæ ‡ç­¾åˆ†ç±»ä½“ç³»
åˆ é™¤UNKNOWNæ ·æœ¬ï¼Œåˆ›å»ºç§‘å­¦åˆç†çš„å¿ƒè„æ ‡ç­¾åˆ†ç±»
"""

import pandas as pd
import numpy as np
import re
from collections import Counter

class RefinedECGLabelSystem:
    """åŸºäºECGFounderè®ºæ–‡çš„ç²¾ç»†åŒ–ECGæ ‡ç­¾ç³»ç»Ÿ"""
    
    def __init__(self):
        # åŸºäºECGFounderè®ºæ–‡Table S4çš„150ä¸ªæ ‡ç­¾ï¼Œé€‰æ‹©é€‚åˆMIMICçš„æ ¸å¿ƒæ ‡ç­¾
        # ä¼˜å…ˆé€‰æ‹©ä¸´åºŠé‡è¦ä¸”åœ¨MIMICæ•°æ®ä¸­å¸¸è§çš„æ ‡ç­¾
        
        self.core_labels = {
            # 1. æ­£å¸¸èŠ‚å¾‹ (Normal Rhythms)
            'NORMAL_SINUS_RHYTHM': {
                'patterns': [r'normal sinus rhythm', r'sinus rhythm$'],
                'exclude': [r'bradycardia', r'tachycardia', r'arrhythmia', r'abnormal']
            },
            'NORMAL_ECG': {
                'patterns': [r'normal ecg', r'normal electrocardiogram'],
                'exclude': [r'except', r'otherwise', r'abnormal']
            },
            
            # 2. å¿ƒå¾‹å¤±å¸¸ - å¿ƒåŠ¨è¿‡ç¼“ (Bradyarrhythmias)  
            'SINUS_BRADYCARDIA': {
                'patterns': [r'sinus bradycardia']
            },
            'MARKED_SINUS_BRADYCARDIA': {
                'patterns': [r'marked sinus bradycardia', r'severe bradycardia']
            },
            
            # 3. å¿ƒå¾‹å¤±å¸¸ - å¿ƒåŠ¨è¿‡é€Ÿ (Tachyarrhythmias)
            'SINUS_TACHYCARDIA': {
                'patterns': [r'sinus tachycardia']
            },
            'ATRIAL_FIBRILLATION': {
                'patterns': [r'atrial fibrillation', r'afib', r'a-fib']
            },
            'ATRIAL_FLUTTER': {
                'patterns': [r'atrial flutter']
            },
            'SUPRAVENTRICULAR_TACHYCARDIA': {
                'patterns': [r'supraventricular tachycardia', r'svt']
            },
            'VENTRICULAR_TACHYCARDIA': {
                'patterns': [r'ventricular tachycardia', r'v-tach', r'vtach']
            },
            
            # 4. ä¼ å¯¼å¼‚å¸¸ (Conduction Abnormalities)
            'RIGHT_BUNDLE_BRANCH_BLOCK': {
                'patterns': [r'right bundle branch block', r'rbbb']
            },
            'LEFT_BUNDLE_BRANCH_BLOCK': {
                'patterns': [r'left bundle branch block', r'lbbb']
            },
            'INCOMPLETE_RIGHT_BUNDLE_BRANCH_BLOCK': {
                'patterns': [r'incomplete right bundle branch block', r'incomplete rbbb']
            },
            'LEFT_ANTERIOR_FASCICULAR_BLOCK': {
                'patterns': [r'left anterior fascicular block', r'lafb']
            },
            'AV_BLOCK_FIRST_DEGREE': {
                'patterns': [r'1st degree av block', r'first degree av block', r'prolonged pr']
            },
            
            # 5. å¿ƒè‚Œæ¢—æ­» (Myocardial Infarction)
            'ANTERIOR_INFARCT': {
                'patterns': [r'anterior infarct', r'anterior mi']
            },
            'INFERIOR_INFARCT': {
                'patterns': [r'inferior infarct', r'inferior mi']
            },
            'LATERAL_INFARCT': {
                'patterns': [r'lateral infarct', r'lateral mi']
            },
            'SEPTAL_INFARCT': {
                'patterns': [r'septal infarct', r'septal mi']
            },
            'ACUTE_MI': {
                'patterns': [r'acute mi', r'acute myocardial infarction', r'stemi', r'acute infarct']
            },
            
            # 6. å¿ƒå®¤è‚¥å¤§ (Ventricular Hypertrophy)
            'LEFT_VENTRICULAR_HYPERTROPHY': {
                'patterns': [r'left ventricular hypertrophy', r'lvh']
            },
            'RIGHT_VENTRICULAR_HYPERTROPHY': {
                'patterns': [r'right ventricular hypertrophy', r'rvh']
            },
            
            # 7. ç”µè½´åç§» (Axis Deviation)
            'LEFT_AXIS_DEVIATION': {
                'patterns': [r'left axis deviation', r'lad\b']
            },
            'RIGHT_AXIS_DEVIATION': {
                'patterns': [r'right axis deviation', r'rad\b']
            },
            
            # 8. å¤æåŒ–å¼‚å¸¸ (Repolarization Abnormalities)
            'NONSPECIFIC_T_WAVE_ABNORMALITY': {
                'patterns': [r'nonspecific t wave abnormality', r't wave abnormality']
            },
            'NONSPECIFIC_ST_ABNORMALITY': {
                'patterns': [r'nonspecific st abnormality', r'st abnormality']
            },
            'ST_ELEVATION': {
                'patterns': [r'st elevation']
            },
            'ST_DEPRESSION': {
                'patterns': [r'st depression']
            },
            
            # 9. æ—©æ (Premature Complexes)
            'PREMATURE_VENTRICULAR_COMPLEXES': {
                'patterns': [r'premature ventricular complex', r'pvc', r'ventricular ectopy']
            },
            'PREMATURE_ATRIAL_COMPLEXES': {
                'patterns': [r'premature atrial complex', r'pac', r'atrial ectopy']
            },
            
            # 10. èµ·æå™¨èŠ‚å¾‹ (Paced Rhythms)
            'VENTRICULAR_PACED_RHYTHM': {
                'patterns': [r'ventricular.*paced', r'v.*paced']
            },
            'ATRIAL_PACED_RHYTHM': {
                'patterns': [r'atrial.*paced', r'a.*paced']
            },
            
            # 11. ä½ç”µå‹å’Œå…¶ä»– (Low Voltage & Others)
            'LOW_VOLTAGE_QRS': {
                'patterns': [r'low voltage', r'low qrs voltage']
            },
            'LEFT_ATRIAL_ENLARGEMENT': {
                'patterns': [r'left atrial enlargement', r'lae']
            },
            'RIGHT_ATRIAL_ENLARGEMENT': {
                'patterns': [r'right atrial enlargement', r'rae']
            }
        }
        
        # è®¡ç®—æ€»æ ‡ç­¾æ•°
        self.total_labels = len(self.core_labels)
        print(f"ğŸ“Š ç²¾ç»†åŒ–æ ‡ç­¾ç³»ç»ŸåŒ…å« {self.total_labels} ä¸ªæ ¸å¿ƒå¿ƒè„ç–¾ç—…æ ‡ç­¾")
    
    def preprocess_diagnosis_text(self, text):
        """è¯Šæ–­æ–‡æœ¬é¢„å¤„ç†"""
        if pd.isna(text) or not isinstance(text, str):
            return ""
        
        text = text.lower().strip()
        text = re.sub(r'[^\w\s-]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        # åŒ»å­¦æœ¯è¯­æ ‡å‡†åŒ–
        medical_abbrev = {
            'ecg': 'electrocardiogram',
            'mi': 'myocardial infarction',
            'av': 'atrioventricular',
            'lvh': 'left ventricular hypertrophy',
            'rvh': 'right ventricular hypertrophy',
            'rbbb': 'right bundle branch block',
            'lbbb': 'left bundle branch block',
            'afib': 'atrial fibrillation'
        }
        
        for abbrev, full_term in medical_abbrev.items():
            text = re.sub(r'\b' + abbrev + r'\b', full_term, text)
        
        return text
    
    def classify_diagnosis(self, diagnosis_text):
        """ä½¿ç”¨ç²¾ç»†åŒ–è§„åˆ™è¿›è¡Œè¯Šæ–­åˆ†ç±»"""
        if not diagnosis_text:
            return []
        
        labels = []
        processed_text = self.preprocess_diagnosis_text(diagnosis_text)
        
        for label, rule_config in self.core_labels.items():
            # æ£€æŸ¥åŒ¹é…æ¨¡å¼
            for pattern in rule_config['patterns']:
                if re.search(pattern, processed_text):
                    # æ£€æŸ¥æ’é™¤æ¡ä»¶
                    if 'exclude' in rule_config:
                        excluded = any(re.search(excl, processed_text) 
                                     for excl in rule_config['exclude'])
                        if not excluded:
                            labels.append(label)
                            break
                    else:
                        labels.append(label)
                        break
        
        return labels
    
    def analyze_mimic_labels(self, mimic_path):
        """åˆ†æMIMICæ•°æ®é›†çš„æ ‡ç­¾åˆ†å¸ƒ"""
        print("ğŸ”„ åˆ†æMIMICæ•°æ®é›†æ ‡ç­¾åˆ†å¸ƒ...")
        
        df = pd.read_csv(mimic_path)
        
        all_diagnoses = []
        for i in range(18):  # report_0 to report_17
            col = f'report_{i}'
            if col in df.columns:
                diagnoses = df[col].dropna().tolist()
                all_diagnoses.extend(diagnoses)
        
        # åº”ç”¨æ–°çš„æ ‡ç­¾ç³»ç»Ÿ
        label_counts = Counter()
        processed_records = 0
        
        for diagnosis in all_diagnoses:
            labels = self.classify_diagnosis(diagnosis)
            for label in labels:
                label_counts[label] += 1
            processed_records += 1
            
            if processed_records % 10000 == 0:
                print(f"  å·²å¤„ç† {processed_records} æ¡è¯Šæ–­...")
        
        print(f"âœ… å¤„ç†å®Œæˆï¼Œå…± {processed_records} æ¡è¯Šæ–­")
        print(f"ğŸ“Š è¯†åˆ«å‡ºçš„æ ‡ç­¾åˆ†å¸ƒ:")
        
        total_labels = sum(label_counts.values())
        for label, count in label_counts.most_common():
            percentage = count / total_labels * 100
            print(f"  {label}: {count} ({percentage:.1f}%)")
        
        return label_counts
    
    def generate_clean_dataset(self, mimic_path, output_path):
        """ç”Ÿæˆæ¸…ç†åçš„æ•°æ®é›†ï¼ˆåˆ é™¤UNKNOWNæ ·æœ¬ï¼‰"""
        print("ğŸ”„ ç”Ÿæˆç²¾ç»†åŒ–æ¸…ç†æ•°æ®é›†...")
        
        # åŠ è½½æ•°æ®
        record_list = pd.read_csv(f"{mimic_path}/record_list.csv")
        note_links = pd.read_csv(f"{mimic_path}/waveform_note_links.csv")
        measurements = pd.read_csv(f"{mimic_path}/machine_measurements.csv")
        
        # åˆå¹¶æ•°æ®
        merged = record_list.merge(note_links, on='study_id', how='inner')
        merged = merged.merge(measurements, on='study_id', how='left')
        
        # æŒ‰æ‚£è€…å»é‡
        patient_groups = merged.groupby('subject_id')
        clean_records = []
        
        for subject_id, group in patient_groups:
            latest_record = group.sort_values('study_id').iloc[-1]
            
            # æå–è¯Šæ–­æ–‡æœ¬
            diagnosis_text = ""
            for i in range(18):
                col = f'report_{i}'
                if col in latest_record and pd.notna(latest_record[col]):
                    diagnosis_text += str(latest_record[col]) + " "
            
            # åº”ç”¨æ–°æ ‡ç­¾ç³»ç»Ÿ
            labels = self.classify_diagnosis(diagnosis_text)
            
            # åªä¿ç•™æœ‰æ ‡ç­¾çš„è®°å½•ï¼ˆåˆ é™¤UNKNOWNï¼‰
            if labels:
                # åˆ›å»ºç‹¬çƒ­ç¼–ç 
                label_vector = np.zeros(self.total_labels)
                label_names = list(self.core_labels.keys())
                
                for label in labels:
                    if label in label_names:
                        idx = label_names.index(label)
                        label_vector[idx] = 1
                
                clean_record = {
                    'subject_id': latest_record['subject_id'],
                    'study_id': latest_record['study_id'],
                    'labels': label_vector,
                    'label_names': labels,
                    'label_count': len(labels),
                    'diagnosis_text': diagnosis_text.strip(),
                    'ecg_file_path': f"{mimic_path}/files/p{str(latest_record['subject_id'])[:4]}/p{latest_record['subject_id']}/s{latest_record['study_id']}/{latest_record['study_id']}"
                }
                clean_records.append(clean_record)
        
        print(f"âœ… ç”Ÿæˆæ¸…ç†æ•°æ®é›†: {len(clean_records)} æ¡æœ‰æ•ˆè®°å½•")
        
        # ä¿å­˜æ•°æ®é›†
        clean_df = pd.DataFrame(clean_records)
        clean_df.to_csv(f"{output_path}/refined_ecg_dataset.csv", index=False)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        all_labels = []
        for record in clean_records:
            all_labels.extend(record['label_names'])
        
        stats = {
            'total_patients': len(clean_records),
            'total_labels': len(all_labels),
            'unique_labels': len(set(all_labels)),
            'label_distribution': dict(Counter(all_labels)),
            'avg_labels_per_patient': len(all_labels) / len(clean_records)
        }
        
        # ä¿å­˜ç»Ÿè®¡
        import json
        with open(f"{output_path}/refined_statistics.json", 'w') as f:
            json.dump(stats, f, indent=2)
        
        return clean_records, stats

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ MIMIC-ECGç²¾ç»†åŒ–æ ‡ç­¾ç³»ç»Ÿ")
    print("åŸºäºECGFounderè®ºæ–‡(2410.04133v4.pdf)")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç²¾ç»†åŒ–æ ‡ç­¾ç³»ç»Ÿ
    label_system = RefinedECGLabelSystem()
    
    # è®¾ç½®è·¯å¾„
    mimic_path = "/Users/zixiang/ecg/mimic-iv-ecg-diagnostic-electrocardiogram-matched-subset-1.0"
    output_path = "/Users/zixiang/PycharmProjects/Master-Thesis/refined_ecg_data"
    
    import os
    os.makedirs(output_path, exist_ok=True)
    
    # åˆ†æMIMICæ ‡ç­¾åˆ†å¸ƒ
    measurements_path = f"{mimic_path}/machine_measurements.csv"
    label_counts = label_system.analyze_mimic_labels(measurements_path)
    
    # ç”Ÿæˆæ¸…ç†æ•°æ®é›†
    clean_records, stats = label_system.generate_clean_dataset(mimic_path, output_path)
    
    print("\nğŸ‰ ç²¾ç»†åŒ–å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“Š æœ€ç»ˆæ•°æ®é›†ç»Ÿè®¡:")
    print(f"  æ€»æ‚£è€…æ•°: {stats['total_patients']}")
    print(f"  å¹³å‡æ¯æ‚£è€…æ ‡ç­¾æ•°: {stats['avg_labels_per_patient']:.2f}")
    print(f"  æ ‡ç­¾ç±»åˆ«æ•°: {stats['unique_labels']}")
    
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"  æ•°æ®é›†: {output_path}/refined_ecg_dataset.csv")
    print(f"  ç»Ÿè®¡: {output_path}/refined_statistics.json")

if __name__ == "__main__":
    main()